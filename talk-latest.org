* Introduction

  Hi, I'm Calvin, a second year PhD student here. Lately I have been
  working a bit on the Vellvm project, which is a Coq semantics for
  the LLVM intermediate representation. Part of my work on this
  project has been on the handling of undefined behaviour and
  unspecified values, which we are going to talk a little bit about
  today.

  This talk isn't for anything in particular, it's just for my own
  understanding, and to talk a little bit about this weird area of
  compilers and programming languages.

  Plus you get to watch me squirm in front of an audience. Wonderful!

* What is undefined behaviour?

  Undefined behaviour is really exactly what it sounds like. It's
  behaviour that hasn't been defined for a programming language.

  Done.

  This is a pretty simple definition, but it's easy to conflate it
  with a few things, and it's also easy to get confused because it
  really doesn't say much about what it means for something to be UB.

  It's also a very language dependent thing. What may be considered UB
  in one language may be perfectly well defined in another. This can
  get confusing, and makes it somewhat difficult to nail down what
  undefined behaviour is, because... Well, it depends!

* What happens when you encounter UB?

  So, keeping in mind that I still haven't told you what UB is... What
  happens when you encounter undefined behaviour?

  Anything.

  Yes, really. Anything. The behaviour of undefined behaviour, being,
  well, undefined, means that you can't really expect any particular
  behaviour when it is encountered.

  Often the compiler is going to do whatever is most efficient, or
  most convenient in these cases, which may very well not be what you
  expect. This includes, but is in no way limited to:
  
  - noop, and then continue as normal
  - halt
  - halt *and* catch fire
  - erase the hard drive
    + no, seriously. Erase the hard drive.
    + https://kristerw.blogspot.com/2017/09/why-undefined-behavior-may-call-never.html
  - time travel
    + no, really.
    + https://devblogs.microsoft.com/oldnewthing/?p=633
  - nasal demons?
    + https://en.wikipedia.org/wiki/Nasal_demons

* Why is this useful?

  So, why have undefined behaviour at all? It seems kind of crazy to
  have these little time bombs in your programming language. Can we
  have a programming language without?

  Absolutely!

  But, what would such a programming language look like? Most
  programming languages are expressive enough that you can get
  yourself in a lot of trouble, like say, indexing out of bounds of an
  array. Because it's undecidable in general to ensure your programs
  are well behaved, in order to have well-specified behaviour these
  programs need dynamic sanity checks to always raise an exception in
  such a case.

  Of course, certain kinds of sanity checks may be performed at
  compile time. A common example of this is static type checking which
  ensures operations are only performed on values with sensible types,
  but this usually only gets you so far before becoming rather
  cumbersome, and in many of these languages things like dynamic
  bounds checking is still very common.

  So, undefined behaviour is the alternative to either having dynamic
  checks, or verifying properties with static checks. You may not want
  to have dynamic checks because it's expensive at run time, and you
  may not be able to have a static check because the property is
  undecidable in general... 

  So, just... Don't... Check.

  Languages like C put the burden on the programmers plate and say
  "you make sure this doesn't happen!"

  While this may seem a little nuts, undefined behaviour essentially
  gives the compiler extra axioms to reason about your code. The
  programmer is supposed to ensure that undefined behaviour can't
  happen, so the compiler can assume that anything it's compiling does
  not exhibit undefined behaviour. This is not without risks,
  programmers make mistakes, but this can actually be really useful,
  and more accurately reflect programmer intent.

  For instance, take this simple piece of code

  #+begin_src c
    a + b < a + c
  #+end_src
  
  You might think, "bah"! I don't want to do two extra additions, the
  compiler should be able to rewrite this to:

  #+begin_src c
    b < c
  #+end_src

  and, in fact, C compilers will happily do this optimization...

  But isn't it... wrong? After all, what if ~a + b~ overflows, resulting in a negative number?

  #+begin_src c
  1 + INT_MAX < 1 + 3
  // This evaluates to
  INT_MIN < 4 == True

  // But...
  INT_MAX < 3 == False
  #+end_src

  However, in C signed integer overflow is undefined behaviour, which
  essentially means that we don't care about the result of addition in
  such corner cases, we'll just assume that good programs don't do
  such silly things, and then on any valid program which doesn't
  exhibit undefined behaviour the optimization does what you expect.

  So, in some sense undefined behaviour can help the compiler to make
  optimizations based on how programmers expect things to be
  used. Generally speaking you don't want integers to overflow, you
  want to assume that all of the values you operate on actually fit in
  your data type, and you want to reason about code based on that
  simpler semantics which holds almost always. It comes with some
  extra burden, the programmer has to make sure that the invariant "no
  signed overflow occurs" actually holds, otherwise they risk the
  compiler transforming their code in unexpected ways, but this is a
  tradeoff and we do get something from it --- higher performance
  code.

* Pointer aliasing

  So, UB can make optimizations match programmer intuitions a little
  better, but undefined behaviour can also allow compilers to make
  optimizations based on invariants whose proofs are undecidable in
  general.

  For instance, it might be really nice to optimize this:

  #+begin_src c
    void sum(double *total, double *array, size_t len )
    {
        ,*total = 0;
        for (size_t i=0; i<len; i++) {
            ,*total += array[i];
        }
    }
  #+end_src

  To this version which only has to write the total to memory once at the end:

  #+begin_src c
    void sum(double *total, double *array, size_t len )
    {
        double local_total = 0;
        for (size_t i=0; i<len; i++) {
            local_total += array[i];
        }

        ,*total = local_total;
    }
  #+end_src

  Unfortunately, this behaves differently than the original program
  when ~total~ is an address in the array. If ~total~ aliases
  ~array[i]~ for some ~i~, then we have to make sure we store the
  ~total~ before we add ~array[i]~, because this will change the value
  of ~array[i]~.

  C, assumes that the pointers can alias, so it can't make this
  optimization and has to perform a write every time the loop's body
  is executed. Other programming languages like Fortran, however, make
  a different assumption, and say that the programmer is responsible
  for ensuring that the pointer arguments to the function don't alias,
  and that if two pointers are passed in that do alias the result is
  undefined behaviour (so, the compiler can do whatever, who
  cares). This is less convenient for the programmer, but it lets
  Fortran be *really* fast, so why not?

  Furthermore, while it may seem crazy for Fortran to make this
  assumption, I believe Rust ensures that mutable pointers can not
  alias. So, the Rust compiler essentially has a proof that they don't
  alias, and it makes sense to forget this proof and just say "oh it
  doesn't happen" at the level of an intermediate representation like
  LLVM IR.

  Interestingly, C actually does provide a keyword to tell the compiler
  "trust me, these pointers don't alias", allowing C compilers to make
  the same set of optimizations, just with an extra tag.

  #+begin_src c
    void sum(double* restrict total, double* restrict array, size_t len )
    {
        ,*total = 0;
        for (size_t i=0; i<len; i++) {
            ,*total += array[i];
        }
    }
  #+end_src

* How powerful is undefined behaviour? Can it time travel?

  # Should this be here, or somewhere else?
 So, this is a bit of a side note. It seems like this undefined
 behaviour thing is really useful, for the compiler anyway. The
 compiler can just assume that these bad cases don't happen, and then
 it can do whatever it wants in these bad situations.

 But how far does this extend? It seems like there's a couple of camps
 with respect to this, and I'm not really sure who to believe.

 One camp says that valid programs never exhibit UB, so if there's a
 branch where UB is always executed, we can just remove that branch
 entirely... So, for something like:

 #+begin_src c
   char inp = getchar();
   if ('A' == inp) {
       printf("Hello, world!\n");
       x = 1 / 0;
   }
 #+end_src

 The if statement can just be optimized to a noop, never printing
 "Hello, world!", even though that happens before the division
 by 0. This is because if we go down this path of execution, we're
 guaranteed to encounter UB. Therefore we clearly can't ever execute
 this branch, which means ~c~ must also always be false, and this if
 statement can just be removed. The compiler seems to conclude that no
 user will ever input ~A~, and all is right with the world.

 This seems a bit extreme, though! A gentler semantics for UB is to
 assume that anything can happen once UB is exhibited, but not
 before. So, perhaps we can just get rid of the bad division, but no
 more.

 #+begin_src c
   char inp = getchar();
   if ('A' == inp) {
       printf("Hello, world!\n");
       // x = 1 / 0;
   }
 #+end_src

 I believe that CompCert (and Vellvm as well) take this more
 conservative approach. It's certainly more stable than the former
 approach (in fact, it's also a refinement of it), and it does seem to
 make more sense from the perspective that none of the prior
 operations exhibit undefined behaviour, so it seems a bit silly to
 have this time traveling undefined behaviour... But I can also see an
 argument for the more aggressive version. The compiler can prove that
 this path will exhibit UB, but it also assumes that UB doesn't
 happen. Therefore, the program shouldn't go down this path!

 The primary difference here, is that the more potent option assumes
 that UB /cannot/ happen, while the latter merely states that
 triggering UB means /anything/ can happen.

 I'm not really sure what the right choice is. For instance, the C++
 standard, for instance, seems to explicitly state that this time
 traveling is allowed.

 #+begin_example
   However, if any such execution contains an undefined operation,
   this International Standard places no requirement on the
   implementation executing that program with that input
   (not even with regard to operations preceding the
   first undefined operation).
 #+end_example

 Again, UB seems to be somewhat of an underspecified concept itself,
 and I think both options are perfectly reasonable, as long as
 everybody involved has some idea of how UB is actually treated,
 particularly with an IR. If LLVM IR has the same time traveling
 behaviour for UB, that's perfectly fine and will allow for even more
 aggressive optimizations, but this (and the myriad of ways you can
 exhibit UB) need to be fully understood by the compiler writers, and
 I'm not sure this is well agreed upon.

* Undefined behaviour in LLVM

  So, undefined behaviour does have its uses. And whether or not you
  think it's a good idea to pass the burden of undefined behaviour
  onto the programmer, it seems to make a lot of sense for an
  intermediate representation used for optimizations, like LLVM.

  Undefined behaviour is a way of passing down invariants other stages
  of the compiler (or programmer-compiler stack) could prove, and that
  an IR like LLVM can just assume.

  In fact, I think it makes a lot of sense to have more control over
  "undefined behaviour" in an intermediate language like LLVM,
  particularly if the IR is intended as a target for multiple
  programming languages, which might handle UB very differently.

  One example for how this could look already exists in LLVM IR. You
  can control what's considered undefined behaviour for add
  instructions.

  #+begin_src llvm
    <result> = add <ty> <op1>, <op2>          ; yields ty:result
    <result> = add nuw <ty> <op1>, <op2>      ; yields ty:result
    <result> = add nsw <ty> <op1>, <op2>      ; yields ty:result
    <result> = add nuw nsw <ty> <op1>, <op2>  ; yields ty:result
  #+end_src

  By default addition is a fully defined operation, with overflow
  being the result modulo $2^n$, and with signed integers having a
  two's complement representation. The ~nuw~ and ~nsw~ flags control
  whether relying on a result that overflows is undefined behaviour
  for unsigned and signed addition respectively. Similarly the ~fadd~
  floating point addition instruction has similar semantics-toggling
  flags to allow for fast math optimizations, which is kind of neat.

  This degree of control seems really useful, and you could imagine
  having annotations for LLVM functions that for instance say "these
  two pointers don't alias", which could be really useful for
  programming languages like Rust which can guarantee that pointer
  arguments don't alias statically, and also useful for things like
  Fortran which put the burden of ensuring there's no aliasing on
  programmers. Everybody wins.

  Having a type system that could allow you to express these
  invariants could be really useful. Explicit annotations can make it
  clear when you actually rely upon undefined behaviour, and we're
  already starting to see some cases of this, like with C99s
  ~restrict~ keyword, which says that a pointer argument does not
  alias with anything. May we live in interesting times.

* Indeterminate values

  So, now we're going to transition to talking a bit about UB and
  handling it in LLVM / Vellvm, but first we have to discuss an
  important part of LLVM. ~undef and ~poison~ values.

  ~undef~ and ~poison~ are what we call indeterminate values,
  particularly ~undef~.  They're intimately related to undefined
  behaviour, but they themselves are not undefined behaviour.  Often
  it is very convenient to be able to say "it doesn't matter what
  value this has", or "this value won't be used", which is essentially
  what ~undef~ and ~poison~ do.

  It's worth prefacing this section with the fact that ~undef~ and
  ~poison~ are sort of... Disputed. Different optimization passes
  treat them differently, and they are not terribly well
  defined. We're currently trying to describe LLVM as it is in Vellvm,
  but it's kind of maddening and there are proposals to change how
  this works entirely because it is well and truly confusing.

** Undef

   LLVM lets you specify that a value is ~undef~, but what exactly
   does this mean? It can be very tempting to think of ~undef~ as
   being UB because of the name, but it's actually a very different
   concept. ~undef~ can be thought of as an "unspecified" or
   "uninitialized" value. This means that the value can take on any
   bit pattern. This might lead to UB if a possible value triggers UB,
   but it also doesn't /have/ to. Here we're just saying "we don't care
   what value this variable takes, make it whatever is convenient at
   the time.

   One point of confusion with ~undef~ is that LLVM really does not
   like to hold a particular representation of an ~undef~ value. Why
   save an arbitrary bit pattern if we don't care about it? So,

   #+begin_src llvm
     %x = i32 undef
     %y = add i32 %x %x
   #+end_src

   Can actually be refined to

   #+begin_src llvm
     %x = i32 undef
     %y = i32 undef  ;; Not just even numbers
   #+end_src

   LLVM basically puts off evaluating ~undef~, and each time an
   ~undef~ is used it can take on a different value. This means that
   the compiler doesn't have to worry about things like saving the value of an
   uninitialized variable.

   This does mean that ~undef~ is somewhat stronger than "we don't
   care what value this variable is assigned", it's essentially "we
   don't care about what value this variable has at all throughout its
   entire life-cycle, even if it changes randomly between uses".

*** More complicated undef

   However, ~undef~ can get more complicated. Our current
   understanding of ~undef~ is that in this case:

   #+begin_src llvm
     %x = i32 undef
     %y = mul i32 %x 2
   #+end_src

   ~%y~ is actually the set of all even numbers, and something like

   #+begin_src llvm
     %z = add i32 %y %y
   #+end_src

   would be the set of all multiples of 2, and not multiples of 4 like
   you might expect, because in this expression ~%y~ is actually
   allowed to take different values each time it's used, it's just
   constrained to be a multiple of 2 each time.

   This seems sort of crazy, because after you compute a value for
   ~%y~ it seems like it would make sense to just save that value and
   use it in both places. This is still a valid thing to do, of
   course, but LLVM lets this behave more broadly, which could
   potentially allow for more optimizations, but we will see how this
   is painful for Vellvm shortly.

*** How is it useful?

    But first, how is ~undef~ actually useful for optimizations?

    One example from the Taming Undefined Behaviour in LLVM paper is this:

    #+begin_src c
      int x;
      if (cond) {
          x = f();
      }

      if (cond2) {
          g(x);
      }
    #+end_src

    Calling ~g(x)~ with an uninitialized value may be undefined
    behaviour, but if you can show that ~cond2~ implies ~cond~. Giving
    ~x~ the value of ~undef~ means that we don't have to care about
    it, and the compiler doesn't have to ensure that ~x~ gets assigned
    some value like ~0~ when it's not necessary.

    # Why not just poison? Well, branching on poison is maybe UB for
    # instance and branching undef is maybe ND choice.

*** How do we handle ~undef~ in Vellvm?

    # Want to mention pick as well. Actually not sure this is necessary.

    ~undef~ handling in Vellvm is fairly complex as we wanted to match
    the apparent semantics of LLVM as much as possible. This means
    that wherever we have ~undef~ we essentially have to construct and
    keep around a full expression.

    #+begin_src c
    (undef + 2) * (3 * undef)  // Left in this complicated form
    #+end_src

    This lets us preserve the set of values that expressions involving
    undef can take on, and we can get the kind of delayed
    nondeterministic choice that we saw previously. We call these
    partially undefined expressions ~uvalues~.

    One problem with this approach, though, is that the interface for
    the memory model is currently not expressive enough. It only
    accepts ~dvalues~, which are concrete values in LLVM. In some
    sense this is reasonable because, because it makes sense that you
    would have to concretize a value in order to store it in memory,
    and it seems like that would fix what the value could be... But it
    does also seem like LLVM permits the compiler to treat values in
    memory as though they can be partially undefined as well. So,
    Vellvm doesn't support storing partially defined values in memory
    right now, but we think we can improve this in the future.

    Having all of this ~uvalue~ stuff does make the interpreter /
    model much more complicated, though. We have to have pick events
    to collapse the nondeterminism of these ~undef~ structures
    whenever a side-effecting operation occurs. These pick events can
    be handled however we want in Vellvm, currently the main
    interpreter just sets all ~undef~ values to 0.

    We also have a propositional model which essentially builds up a
    predicate which is provable whenever UB does not occur. In certain
    cases, like when performing a div, we add additional constraints
    like "the value of the denominator can not be 0".

** Poison

   ~poison~ is an even stronger result than ~undef~, and we can
   actually always relax ~poison~ to ~undef~.

   Generally much simpler to understand than ~undef~, the result of
   pretty much any operation on ~poison~ is just ~poison~, and if it's
   used in any side-effecting way then it raises undefined behaviour.

*** How is it useful?

    ~poison~ is essentially a kind of deferred undefined behaviour.

    This can be really useful for a kind of speculative execution. For
    instance if you want to perform loop invariant code motion,
    optimizations which lift loop invariant expressions outside of
    loops. For instance:

    #+begin_src c
      for (size_t i = 0; i <= n; ++i) {
          a[i] = x + 1;
       }
    #+end_src

    We want ~x + 1~ to be UB if it overflows, but not immediate UB because we want to be able to do this:

    #+begin_src c
      int y = x + 1;
      for (size_t i = 0; i <= n; ++i) {
          a[i] = y;
       }
    #+end_src

    Similarly:

    #+begin_src c
      for (int i = 0; i <= n; ++i) {
          a[(size_t)i] = 42;
      }
    #+end_src

    Could potentially be optimized to:

    #+begin_src c
      for (size_t i = 0; i <= n; ++i) {
          a[i] = 42;
      }
    #+end_src

    That is, you can lift the sign extension of the index out of the
    loop. However, this is only valid if it were UB for ~i~ to
    overflow beforehand, since ~size_t~ is bigger than ~i~. If ~i~
    overflowing just resulted in ~undef~, then we would still only
    index within the range of integers, so this optimization which
    allows indexing outside of this region would not be justified.

*** How do we handle ~poison~ in Vellvm?

    Poison in Vellvm is much simpler than ~undef~ because pretty much
    anything that operates on poison results in poison, and there are
    a few places where we use poison to trigger a UB event, 

** ~poison~ vs ~undef~

   # finish the part with undef justifying an optimization.

   I don't want to get too into the weeds about the differences
   between ~poison~ and ~undef~. It's a bit confusing that LLVM has
   both of these things, and they're slightly different. ~poison~ is
   stronger than ~undef~, and essentially says that if the value is
   used then it's undefined behaviour. ~undef~ means that the value
   can take on any arbitrary bit pattern, kind of like an
   uninitialized variable. They both justify different optimizations,
   but it's also inconsistent in LLVM.

   For instance if overflow was ~undef~ instead of ~poison~ then you
   wouldn't be able to optimize

   #+begin_src c
   a + 1 > a
   #+end_src

   to

   #+begin_src c
   true // Or I guess 1 in C... Whatever. Something something type system.
   #+end_src

   If you get ~poison~ when ~a + 1~ overflows, then this is undefined
   behaviour, so we can just ignore this case and perform the
   optimization that we want.

   If instead you got ~undef~ when ~a + 1~ overflows, then we would be
   able to refine to any arbitrary value for ~a + 1~, and optimize
   based on that. However, if ~a + 1~ overflows, then this means that
   ~a == INT_MAX~ which is no good because then we can't pick anything
   for ~a + 1~ which is larger than ~INT_MAX~, so we can't just pick a
   value that makes this expression a constant ~true~.

* TODO Refinement and Vellvm

  Refinment relations in Vellvm have to take into account undefined
  values. This means that we have to have a refinement relation on
  ~uvalues~, the expressions representing partially defined values.

  #+begin_src coq
    (* Refinement relation for uvalues *)
    Inductive refine_uvalue: uvalue -> uvalue -> Prop :=
    | UndefPoison: forall t, refine_uvalue (UVALUE_Undef t) UVALUE_Poison (* CB / YZ: TODO, type for poison? *)
    | RefineConcrete: forall uv1 uv2, (forall dv, concretize uv1 dv -> concretize uv2 dv) -> refine_uvalue uv1 uv2
    .
  #+end_src

  So, ~undef~ refines ~poison~, and ~uv1~ refines ~uv2~ if any
  concretization of ~uv1~ is also a concretization of ~uv2~.

  #+begin_src coq
    (* Refinement of uninterpreted mcfg *)
    Definition refine_L0: relation (itree L0 uvalue) := eutt refine_uvalue.

    (* Refinement of mcfg after globals *)
    Definition refine_res1 : relation (global_env * uvalue)
      := TT × refine_uvalue.

    (* ... *)
  #+end_src
  
  And then we have a bunch of levels of refinements for reasoning
  about LLVM programs at different levels of interpretation. Mostly
  the LLVM program ~l1~ is a refinement of ~l2~ if the denotated
  itrees are equivalent up to ~Tau~, and the resulting ~uvalue~ is
  equivalent up to ~Tau~.
  
  #+begin_src coq
    (* Refinement for after interpreting pick. *)
    Definition refine_L4 : relation ((itree L4 (memory * (local_env * stack * (global_env * uvalue)))) -> Prop)
      := fun ts ts' => forall t, ts t -> exists t', ts' t' /\ eutt refine_res3 t t'.
  #+end_src

  And there are more interesting relations under our propositional model.

* A better future? Freeze / thaw semantics
** Freeze / Thaw

   undef and poison are pretty confusing. One method of making this
   better is the proposed freeze / thaw semantics which basically
   removes ~undef~ in favor of ~poison~, which is generally much
   better behaved, and then adds a ~freeze~ instruction which turns a
   ~poison~ value into a nondeterministic choice like ~undef~, but
   which is immediately fixed to a value, instead of having the weird
   ~undef~ lazy semantics.

   This semantics is much easier to understand, clarifying some things
   like branching on poison being UB, and making the ~undef~
   equivalent ~freeze~ of ~poison more of what you would expect, while
   still justifying a good number of optimizations.

   Furthermore the behaviour of ~undef~ can still largely be
   recovered, it just has to be explicit with multiple ~freeze~
   instructions.

   If you want to know more, read Taming Undefined Behaviour in LLVM.

** Can vellvm support this

   - Should be a fairly trivial change due to how everything is set up.
   - Currently don't want to support it because it would mean that
     Vellvm would have freeze instructions, which LLVM currently
     doesn't have :(.

* What about erasing the hard drive?

  - Short explanation of this if there's time.

* Bibliography

- https://blog.regehr.org/archives/1496
- John Regehr's Guide to UB is good
  + https://blog.regehr.org/archives/213
  + https://blog.regehr.org/archives/226
  + https://blog.regehr.org/archives/232
- http://www.cs.utah.edu/~regehr/papers/undef-pldi17.pdf
- https://www.cl.cam.ac.uk/~pes20/cerberus/cerberus-popl2019.pdf
- https://kristerw.blogspot.com/2017/09/why-undefined-behavior-may-call-never.html
- https://devblogs.microsoft.com/oldnewthing/?p=633

* Introduction

  Hi, I'm Calvin, a second year PhD student here. Lately I have been
  working a bit on the Vellvm project, which is a Coq semantics for
  the LLVM intermediate representation. Part of my work on this
  project has been on the handling of undefined behaviour and
  unspecified values, which we are going to talk a little bit about
  today.

  This talk isn't for anything in particular, it's just for my own
  understanding, and to talk a little bit about this weird area of
  compilers and programming languages.

  Plus you get to watch me squirm in front of an audience. Wonderful!

* What is undefined behaviour?

  Undefined behaviour is really exactly what it sounds like. It's
  behaviour that hasn't been defined for a programming language.

  Done.

  This is a pretty simple definition, but it's easy to conflate it
  with a few things, and it's also easy to get confused because it
  really doesn't say much about what it means for something to be UB.

  It's also a very language dependent thing. What may be considered UB
  in one language may be perfectly well defined in another. This can
  get confusing, and makes it somewhat difficult to nail down what
  undefined behaviour is, because... Well, it depends!

* What happens when you encounter UB?

  So, keeping in mind that I still haven't told you what UB is... What
  happens when you encounter undefined behaviour?

  Anything.

  Yes, really. Anything. The behaviour of undefined behaviour, being,
  well, undefined, means that you can't really expect any particular
  behaviour when it is encountered.

  Often the compiler is going to do whatever is most efficient, or
  most convenient in these cases, which may very well not be what you
  expect. This includes, but is in no way limited to:
  
  - noop, and then continue as normal
  - halt
  - halt *and* catch fire
  - erase the hard drive
    + no, seriously. Erase the hard drive.
    + https://kristerw.blogspot.com/2017/09/why-undefined-behavior-may-call-never.html
  - time travel
    + no, really.
    + https://devblogs.microsoft.com/oldnewthing/?p=633
  - nasal demons?
    + https://en.wikipedia.org/wiki/Nasal_demons

* Why is this useful?

  So, why have undefined behaviour at all? It seems kind of crazy to
  have these little time bombs in your programming language. Can we
  have a programming language without? Absolutely! But it does give
  the compiler for such programming languages less flexibility for how
  to handle optimizations and corner cases.

  You see, undefined behaviour essentially gives the compiler extra
  axioms to reason about your code. The compiler can essentially
  assume that undefined behaviour is not triggered in a program, which
  can actually be really useful, and more accurately reflect
  programmer intent.

  Take for instance this simple piece of code

  #+begin_src c
    a + b < a + c
  #+end_src
  
  You might think, "bah"! I don't want to do two extra additions, the
  compiler should be able to rewrite this to:

  #+begin_src c
    b < c
  #+end_src

  and, in fact, C compilers will happily do this optimization...

  But isn't it... wrong? After all, what if ~a + b~ overflows, resulting in a negative number?

  #+begin_src c
  1 + INT_MAX < 1 + 3
  // This evaluates to
  INT_MIN < 4 == True

  // But...
  INT_MAX < 3 == False
  #+end_src

  However, in C signed integer overflow is undefined behaviour, which
  essentially says that we don't care what the result of that
  operation is in such corner cases, we'll just assume that good
  programs don't do such silly things, and then on any valid program
  which doesn't exhibit undefined behaviour the optimization does what
  you expect.

  So, in some sense undefined behaviour can help the compiler to make
  optimizations based on how programmers actually expect things to be
  used. Generally speaking you don't want integers to overflow, you
  want to assume that all of the values you operate on actually fit in
  your data type, and you want to reason about code based on that
  simpler semantics which holds almost always. It comes with some
  extra burden, the programmer has to make sure that the invariant "no
  signed overflow occurs" actually holds, otherwise they risk the
  compiler transforming their code in unexpected ways, but this is a
  tradeoff and we do get something from it --- higher performance code.

* Pointer aliasing

  Undefined behaviour can also allow compilers to make optimizations
  based on invariants whose proofs are undecidable in general.

  For instance, it might be really nice to optimize this:

  #+begin_src c
    void sum(double *total, double *array, size_t len )
    {
        ,*total = 0;
        for (size_t i=0; i<len; i++) {
            ,*total += array[i];
        }
    }
  #+end_src

  To this version which only has to write the total to memory once at the end:

  #+begin_src c
    void sum(double *total, double *array, size_t len )
    {
        double local_total = 0;
        for (size_t i=0; i<len; i++) {
            local_total += array[i];
        }

        ,*total = local_total;
    }
  #+end_src

  Unfortunately, this behaves differently than the original program
  when ~total~ is an address in the array. If ~total~ aliases
  ~array[i]~ for some ~i~, then we have to make sure we store the
  ~total~ before we add ~array[i]~, because this will change the value
  of ~array[i]~.

  C, assumes that the pointers can alias, so it can't make this
  optimization and has to perform a write every time the loop's body
  is executed. Other programming languages like Fortran, however, make
  a different assumption, and say that the programmer is responsible
  for ensuring that the pointer arguments to the function don't alias,
  and that if two pointers are passed in that do alias the result is
  undefined behaviour (so, the compiler can do whatever, who
  cares). This is less convenient for the programmer, but it lets
  Fortran be *really* fast, so why not?

  Furthermore, while it may seem crazy for Fortran to make this
  assumption, I believe Rust ensures that mutable pointers can not
  alias. So, the Rust compiler essentially has a proof that they don't
  alias, and it makes sense to forget this proof and just say "oh it
  doesn't happen" at the level of an intermediate representation like
  LLVM IR.

  Interestingly, C actually does provide a keyword to tell the compiler
  "trust me, these pointers don't alias", allowing C compilers to make
  the same set of optimizations, just with an extra tag.

  #+begin_src c
    void sum(double* restrict total, double* restrict array, size_t len )
    {
        ,*total = 0;
        for (size_t i=0; i<len; i++) {
            ,*total += array[i];
        }
    }
  #+end_src

* How powerful is undefined behaviour? Can it time travel?

  # Should this be here, or somewhere else?
 So, this is a bit of a side note. It seems like this undefined
 behaviour thing is really useful, for the compiler anyway. The
 compiler can just assume that these bad cases don't happen, and then
 it can do whatever it wants in these bad situations.

 But how far does this extend? It seems like there's a couple of camps
 with respect to this, and I'm not really sure who to believe.

 One camp says that valid programs never exhibit UB, so if there's a
 branch where UB is always executed, we can just remove that branch
 entirely... So, for something like:

 #+begin_src c
   char inp = getchar();
   if ('A' == inp) {
       printf("Hello, world!\n");
       x = 1 / 0;
   }
 #+end_src

 The if statement can just be optimized to a noop, never printing
 "Hello, world!", even though that happens before the division
 by 0. This is because if we go down this path of execution, we're
 guaranteed to encounter UB. Therefore we clearly can't ever execute
 this branch, which means ~c~ must also always be false, and this if
 statement can just be removed. The compiler seems to conclude that no
 user will ever input ~A~, and all is right with the world.

 This seems a bit extreme, though! A gentler semantics for UB is to
 assume that anything can happen once UB is exhibited, but not
 before. So, perhaps we can just get rid of the bad division, but no
 more.

 #+begin_src c
   char inp = getchar();
   if ('A' == inp) {
       printf("Hello, world!\n");
       x = 1 / 0;
   }
 #+end_src

 I believe that CompCert (and Vellvm as well) take the latter, more
 conservative approach. This is certainly more stable than the former
 approach (in fact, it's also a refinement of it), and it does seem to
 make more sense from the perspective that none of the prior
 operations exhibit undefined behaviour, so it seems a bit silly to
 have this time traveling undefined behaviour... But I can also see an
 argument for the more aggressive version. The compiler can prove that
 this path will exhibit UB, but it also assumes that UB doesn't
 happen. Therefore, the program shouldn't go down this path!

 The primary difference here, is that the more potent option assumes
 that UB /cannot/ happen, while the latter merely states that
 triggering UB means /anything/ can happen.

 I'm not really sure what the right choice is, though. For instance,
 the C++ standard, for instance, seems to explicitly state that this
 time traveling is allowed.

 #+begin_example
   However, if any such execution contains an undefined operation,
   this International Standard places no requirement on the
   implementation executing that program with that input
   (not even with regard to operations preceding the
   first undefined operation).
 #+end_example

 Again, UB seems to be somewhat of an underspecified concept itself,
 and I think both options are perfectly reasonable, as long as
 everybody involved has some idea of how UB is actually treated,
 particularly with an IR. If LLVM IR has the same time traveling
 behaviour for UB, that's perfectly fine and will allow for even more
 aggressive optimizations, but this (and the myriad of ways you can
 exhibit UB) need to be fully understood by the compiler writers, and
 I'm not sure this is well agreed upon.

* Undefined behaviour in LLVM

  So, undefined behaviour does have its uses. And whether or not you
  think it's a good idea to pass the burden of undefined behaviour
  onto the programmer, it seems to make a lot of sense for an
  intermediate representation like LLVM.

  Undefined behaviour is a way of passing down invariants other stages
  of the compiler (or programmer-compiler stack) could prove, and that
  an IR like LLVM can just assume.

  In fact, I think it makes a lot of sense to have more control over
  "undefined behaviour" in an intermediate language like LLVM,
  particularly if the IR is intended as a target for multiple
  programming languages, which might handle UB very differently.

  One example for how this kind of thing could look already exists in
  LLVM IR. You can control what's considered undefined behaviour for
  add instructions.

  #+begin_src llvm
    <result> = add <ty> <op1>, <op2>          ; yields ty:result
    <result> = add nuw <ty> <op1>, <op2>      ; yields ty:result
    <result> = add nsw <ty> <op1>, <op2>      ; yields ty:result
    <result> = add nuw nsw <ty> <op1>, <op2>  ; yields ty:result
  #+end_src

  By default addition is a fully defined operation, with overflow
  being the result modulo $2^n$, and signed integers having a two's
  complement representation. The ~nuw~ and ~nsw~ flags control whether
  relying on a result that overflows is undefined behaviour for
  unsigned and signed addition respectively. Similarly the ~fadd~
  floating point addition instruction has similar semantics-toggling
  flags to allow for fast math optimizations.

  This degree of control seems really useful, and you could imagine
  having annotations for LLVM functions that for instance say "these
  two pointers don't alias", which could be really useful for
  programming languages like Rust which can guarantee that pointer
  arguments don't alias statically, and also useful for things like
  Fortran which put the burden of ensuring there's no aliasing on
  programmers.

  Having a type system that could allow you to express these
  invariants could be really useful, and explicit annotations could
  make it clear when you actually rely upon undefined behaviour, and
  we're already starting to see some cases of this, like with C99s
  ~restrict~ keyword, which says that a pointer argument does not
  alias with anything. May we live in interesting times.

* LLVM and undefined behaviour

  So, now I'm going to talk a bit about undefined behaviour and
  handling it in LLVM, and in particular Vellvm.

  But first we have to discuss a majorly important part of
  LLVM. ~undef~ and ~poison~ values.

* Indeterminate values

  ~undef~ and ~poison~ are what we call indeterminate values,
  particularly ~undef~.  They're intimately related to undefined
  behaviour, but they themselves are not undefined behaviour.  Often
  it is very convenient to be able to say "it doesn't matter what
  value this has", or "this value won't be used", which is essentially
  what ~undef~ and ~poison~ do.

** Undef

   LLVM lets you specify that a value is ~undef~, but what exactly
   does this mean? Is ~undef~ undefined behaviour? No!

   It can be very tempting to think of ~undef~ as being UB because of
   the name, but it's actually a very different concept. ~undef~ can
   be thought of as an "unspecified" or "uninitialized" value. This
   means that the value can take on any bit pattern.

   One point of confusion with ~undef~ is that LLVM really does not
   like to hold a particular representation of a value that we don't
   care about. So,

   #+begin_src llvm
     %x = i32 undef
     %y = add i32 %x %x
   #+end_src

   Can actually be refined to

   #+begin_src llvm
     %x = i32 undef
     %y = i32 undef  ;; Not just even numbers
   #+end_src

   LLVM basically puts off evaluating ~undef~, and each time an
   ~undef~ is used it can take on a different value. This means that
   the compiler doesn't have to worry about saving the value of an
   uninitialized variable, for instance.

   # Maybe explain "don't care" better.
   This does mean that ~undef~ is somewhat stronger than "we don't
   care what value this variable is assigned", it's essentially "we
   don't care about what value this variable has at all, even if it
   changes randomly between uses".

*** More complicated undef

   However, our current understanding of ~undef~ is that in this case:

   #+begin_src llvm
     %x = i32 undef
     %y = mul i32 %x 2
   #+end_src

   ~%y~ is actually the set of all even numbers, so something like

   #+begin_src llvm
     %z = add i32 %y %y
   #+end_src

   would be the set of all multiples of 2, and not multiples of 4 like
   you might expect, because in this expression ~%y~ is actually
   allowed to take different values each time it's used, it's just
   constrained to be a multiple of 2 each time.

   This seems sort of crazy, because after you compute a value for
   ~%y~ it seems like it would make sense to just save that value and
   use it in both places. This is still a valid thing to do, of
   course, but LLVM lets this behave more broadly, which can
   potentially allow for more optimizations. We'll see how this is
   painful for Vellvm shortly.

*** How is it useful?

    But first, how is ~undef~ actually useful for optimizations?

*** How do we handle ~undef~ in Vellvm?

    ~undef~ handling in Vellvm is fairly complex as we wanted to match
    the apparent semantics of LLVM as much as possible.

    

** Poison

   ~poison~ is an even stronger result than ~undef~.

   - Can always relax to ~undef~.

   Generally much simpler to understand than ~undef~, the result of
   pretty much any operation on ~poison~ is just ~poison~, and if it's
   used in any side-effecting way then it raises undefined behaviour.

*** How is it useful?

    ~poison~ is essentially a kind of deferred undefined behaviour.

    This can be really useful for a kind of speculative execution. For
    instance if you want to perform loop invariant code motion,
    optimizations which lift loop invariant expressions outside of
    loops. For instance:

    #+begin_src c
      while (c) {
          int x = 1 / k;
          printf("%d\n", x);
      }
    #+end_src

    Could potentially be optimized to:

    #+begin_src c
      int x = 1 / k;
      while (c) {
          printf("%d\n", x);
      }
    #+end_src

    But this only works in the case where ~k~ is nonzero.

*** How do we handle ~poison~ in Vellvm?

** ~poison~ vs ~undef~

   I don't want to get too into the weeds about the differences
   between ~poison~ and ~undef~. It's a bit confusing that LLVM has
   both of these things, and they're slightly different. ~poison~ is
   essentially stronger than ~undef~, and essentially says that if the
   value is used then it's undefined behaviour. ~undef~ means that the
   value can take on any arbitrary bit pattern, kind of like an
   uninitialized variable. They both justify different optimizations.

   For instance if overflow was ~undef~ instead of ~poison~ then you
   wouldn't be able to optimize

   #+begin_src c
   a + 1 > a
   #+end_src

   to

   #+begin_src c
   true // Or I guess 1 in C... Whatever. Something something type system.
   #+end_src

   If you get ~poison~ when ~a + 1~ overflows, then this is undefined
   behaviour, so we can just ignore this case and perform the
   optimization that we want.

   If instead you got ~undef~ when ~a + 1~ overflows, then we would be
   able to refine to any arbitrary value for ~a + 1~, and optimize
   based on that. However, if ~a + 1~ overflows, then this means that
   ~a == INT_MAX~ which is no good because then we can't pick anything
   for ~a + 1~ which is larger than ~INT_MAX~, so we can't just pick a
   value that makes this expression a constant ~true~.

   Similarly undef can justify...

* Example of hoisting?

* UB in Vellvm
** Refinement relations

   - Must take into account undef / poison
   - Must handle UB

* A better future? Freeze / thaw semantics
** Freeze / Thaw
*** Why is this better?
** Can vellvm support this

   - Should be a fairly trivial change due to how everything is set up.
   - Currently don't want to support it because it would mean that
     Vellvm would have freeze instructions, which LLVM currently
     doesn't have :(.

* What about erasing the hard drive?

  - Short explanation of this if there's time.

* Bibliography

- https://blog.regehr.org/archives/1496
- John Regehr's Guide to UB is good
  + https://blog.regehr.org/archives/213
  + https://blog.regehr.org/archives/226
  + https://blog.regehr.org/archives/232
- http://www.cs.utah.edu/~regehr/papers/undef-pldi17.pdf
- https://www.cl.cam.ac.uk/~pes20/cerberus/cerberus-popl2019.pdf
- https://kristerw.blogspot.com/2017/09/why-undefined-behavior-may-call-never.html
- https://devblogs.microsoft.com/oldnewthing/?p=633
